---
title: "Simulating Data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Simulating Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(mrScan)
library(DiagrammeR)
library(dplyr)
library(reshape2)
library(ggplot2)
library(TwoSampleMR)
library(GRAPPLE)
set.seed(1)
```

## Introduction

This vignette demonstrates how to use the `sim_mv` function to simulate data and demonstrate
some properties of single variable and multi-variable MR. This vignette uses the `DiagrammeR` 
package for visualization. 

## Introduction to `sim_mv`

The `sim_mv` function generates GWAS summary statistics for multiple traits with specified
linear causal relationships between traits. 

It can be used in two modes, 'general' and 'xyz'.
In 'general' mode, `sim_mv` will generate data from any user specified DAG. 
In 'xyz' mode, `sim_mv` generates data from specific types of DAGs. Both of these modes will
be explained below. 


There are four arguments that are common to both modes:

+ `N`: The GWAS sample size for each trait. This can be a scalar or a vector with length equal to the number of traits generated.
+ `J`: The number of SNPs to simulate.
+ `h2`: The hertiability of each trait. This can be a scalar or a vector with length equal to the number of traits generated.
+ `pi`: The proportion of all SNPs that have a direct effect on each trait. This can be a scalar or a vector with length equal to the number of traits generated.

## Limitations

This code is still in development. It has several limitations, some of which will
be addressed in future versions (marked by (*) below) and some which will probably persist. 

Data generation: 

+ SNPs are generated with no LD (i.e. all SNPs are independent) (*).
+ Direct effect SNPs for each trait are chosen randomly and independently. In the future, I would like to provide an option to specify the proportion of shared direct effect SNPs between pairs of traits or give an option for no sharing. (**)

Graphs:

+ All DAGs are linear and additive
+ There is currently no way to specify effect modification (**)


Other:

+ The function will not verify that supplied graph is acyclic (*).

## General Mode

To use `sim_mv` in 'general' mode, the user specifies, a DAG as a matrix, $G$. The 
$G_{i,j}$ entry specifies the direct effect of variable $i$ on variable $j$. The
diagonal entries of $G$ should be 0. All variables are assumed to have variance 
equal to 1, so $G_{i,j}^2$ is the proportion of variable $j$ variance explained by 
the direct effect of variable $i$. 

For example, the graph below: 

```{r, echo=FALSE, fig.align='center', fig.width = 5}
G <- matrix(c(0, sqrt(0.25), 0, sqrt(0.15), 
              0, 0, 0, sqrt(0.1), 
              sqrt(0.2), 0, 0, -sqrt(0.3), 
              0, 0, 0, 0), nrow = 4, byrow = TRUE)
#colnames(G) <- row.names(G) <- c("X", "Y", "Z", "W")

d <- melt(G) %>%
     filter(value !=0) %>%
     rename(from = Var1, to = Var2)


n <- create_node_df(n = 4, label = c("X", "Y", "Z", "W"), 
                    fontname = "Helvetica", 
                    fontsize = 10, 
                    width = 0.3, 
                    fillcolor = "white", 
                    fontcolor = "black",
                    color = "black", 
                    x = c(0, 1, 1, 2), 
                    y = c(0, -0.5, 1, 0))
e <- create_edge_df(from = d$from, to = d$to, minlen = 1,  color = "black", 
                    label = round(d$value, digits = 3))
g <- create_graph(nodes_df = n, edges_df = e)

render_graph(g)
```

is represented by the matrix

```{r}
G <- matrix(c(0, sqrt(0.25), 0, sqrt(0.15), 
              0, 0, 0, sqrt(0.1), 
              sqrt(0.2), 0, 0, -sqrt(0.3), 
              0, 0, 0, 0), nrow = 4, byrow = TRUE)
colnames(G) <- row.names(G) <- c("X", "Y", "Z", "W")
G
```

To simulate data from this graph, we can use

```{r}
sim_dat1 <- sim_mv(G = G,
                  N = 80000, J = 50000, 
                  h2 = c(0.3, 0.3, 0.5, 0.4), 
                  pi = 800/50000)
```

In the function call above, we specified a GWAS sample size of 60k for every GWAS. 
We gave different heritabilities of each of the four traits (the `h2` argument). 
Every trait has 1000 direct effect SNPs (the `pi` argument). `J` specifies the total number
of variants to generate. 

### xyz Mode


In 'xyz' mode, `sim_mv` will produce data from particular kinds of DAGs. In 'xyz' mode, 
there is an exposure ($X$), an outcome ($Y$), and $K$ other variables, $Z_1, \dots, Z_K$. 

There is a (possibly 0) effect of $X$ on $Y$ specified by the `gamma` argument. 
Variables $Z_1, \dots, Z_K$ can have effects either on or from $X$, $Y$ or both. So
$Z_k$ could be a confounder of $X$ and $Y$ (effects on both variables), a child (collider) of
$X$ and $Y$ (effects from both variables), or a mediator between $X$ and $Y$ (effect from $X$ and to $Y$). 
The program will give an error if the user tries to specify a mediator between $Y$ and $X$ as this would 
create a cycle.
As special cases, any of these effects could be zero. So $Z_k$ could also be a parent only or child only of $X$ or $Y$. 

Effects between each $Z_k$ and $X$ and $Y$ respectively are given in the `tau_xz` and `tau_yz` arguments. 
The direction of these effects is given in the `dir_xz` and `dir_yz` arguments. 
Effect size arguments `gamma`, `tau_xz`, and `tau_yz` are all given as signed proportion of variance explained. 
So if `gamma = -0.3`, The direct effect of $X$ explains 30\% of the variance of $Y$ and the 
effect of $X$ on $Y$ is negative. The direction parameters `dri_xz` and `dir_yz` should
have equal length to `tau_xz` and `tau_yz`. Elements should be 1 if there is an effect on $X$ or $Y$ and -1 if there is an effect from $X$ or $Y$. 

For example, the code

```{r}
sim_dat2 <- sim_mv(tau_xz = c(0.1, -0.15, 0.2, 0.3), 
                   tau_yz = c(0, 0.2, -0.25, 0.15), 
                   dir_xz = c(1, 1, -1, -1), 
                   dir_yz = c(1, 1, -1, 1),
                   gamma = 0.3,
                   N = 40000, J = 50000, 
                   h2 = c(0.3, 0.3, 0.5, 0.4, 0.35, 0.1), 
                   pi = 1000/50000)
```

generates data from the graph


```{r, echo=FALSE, fig.align='center', fig.width = 5}
G <- sim_dat2$direct_trait_effects
#colnames(G) <- row.names(G) <- c("X", "Y", "Z", "W")

d <- melt(G) %>%
     filter(value !=0) %>%
     rename(from = Var1, to = Var2)

n <- create_node_df(n = 6, label = c("X", "Y", "Z1", "Z2", "Z3", "Z4"), 
                    fontname = "Helvetica", 
                    fontsize = 10, 
                    width = 0.3, 
                    fillcolor = "white", 
                    fontcolor = "black",
                    color = "black", 
                    x = c(0, 2, -0.5, 1, 1, 1), 
                    y = c(0, 0, 1, 1, -0.5, -1))
e <- create_edge_df(from = d$from, to = d$to, minlen = 1,  color = "black", 
                    label = round(d$value, digits = 3))
g <- create_graph(nodes_df = n, edges_df = e)

render_graph(g)
```


The weights in the graph give the effect size. Note that this is the square root of the value provided in `tau_xz` and `tau_yz` which specifies the percent variance explained. For example, the effect of $Z_1$ on $X$ is  $0.316 = \sqrt{0.1}$ and the effect of $Z_2$ on $X$ is $-0.387 = - \sqrt{0.15}$. 


### Simulation Object

The `sim_mv` function returns a list with the following elements

+ `beta_hat`, `se_beta_hat`: Simulated GWAS effect estimates and standard errors
+ `direct_SNP_effects`: direct effects of SNPs on traits
+ `B`: True SNP associations. Without LD, this is the same as the total effect of SNPs on traits.
+ `direct_trait_effects`: Matrix of direct effects between traits
+ `total_trait_effects`: Matrix of total effects between traits

When used in general mode, the order of the columns in `beta_hat`, `se_beta_hat`, and `B` corresponds
to the order of variables in `G`. When used in xyz mode, the first column is $X$, the second 
column is $Y$ and subsequent columns are the $Z_k$'s in the order they were provided.

### Exploring MR with simulations

We will use the data generated in the  "General Mode" section to explore MR. 
Suppose we are interested in estimating the effect of $X$ on $W$. The total effect of 
$X$ on $W$ is $0.387 + 0.5\cdot 0.316 = 0.545$. We can confirm this by looking at the (1,4) element of
`total_trait_effects` matrix:

```{r}
sim_dat1$total_trait_effects
```

Valid instruments for measuring this effect are SNPs that have non-zero direct
effect on $X$ but zero direct effect on all other SNPs. Note that direct effects
are assigned randomly, so by chance some SNPs will have direct effects on more than one trait. 


Before we try to apply MR, let's take a look at the **true** total effects of each SNP on $X$ 
plotted against the **true** total effect of each SNP on $Y$. We will color SNPs by 
which of the four variables they directly effect. These categories are tabulated below. We will not plot
the null SNPs (SNPs with no effects on any variables) since these SNPs all correspond
to a point at the origin (recall we are plotting the true effects and not the effect estimates). 

```{r}
te <- data.frame(x_effect = sim_dat1$B[,1], 
                 w_effect = sim_dat1$B[,4], 
                 type = case_when(rowSums(sim_dat1$direct_SNP_effets !=0) == 0 ~ "Null SNPs",
                                  (sim_dat1$total_trait_effects[,1] == 0 & 
                                    rowSums(sim_dat1$direct_SNP_effets[,-1] !=0) == 0) ~ "X Effect SNPs", 
                                  (sim_dat1$total_trait_effects[,3] == 0 & 
                                    rowSums(sim_dat1$direct_SNP_effets[,-3] !=0) == 0) ~ "Z Effect SNPs",
                                  (sim_dat1$total_trait_effects[,2] == 0 & 
                                    rowSums(sim_dat1$direct_SNP_effets[,-2] !=0) == 0) ~ " Y Effect SNPs", 
                                  (sim_dat1$total_trait_effects[,4] == 0 & 
                                    rowSums(sim_dat1$direct_SNP_effets[,-4] !=0) == 0) ~ " W Effect SNPs", 
                                  TRUE ~ "Multiple"))
table(te$type)
```
Below is the plot of the true effects on $X$ vs true effects on $W$. The black line has slope 
equal to the total effect of $X$ on $W$ which we are trying to estimate. 

```{r, fig.width=6}
te %>% filter(type != "Null SNPs") %>%
ggplot() + 
  geom_point(aes(x = x_effect, y = w_effect, color = type), alpha = 0.6) + 
  geom_abline(slope = sim_dat1$total_trait_effects[1,4]) + 
  theme_bw()

```

Notice the following features of the graph: 

+ The SNPS with direct effects on $X$ *only* fall exactly along the black line. 
+ SNPs with direct effects on $Z$ only (the confounder of $X$ and $W$) fall on a different line. 
+ SNPS with direct effects on $W$ or $Y$ only fall on the x-axis -- they have no effect on $X$. 
+ SNPs with direct effects on multiple traits are scattered around the plot. 

Look at the DAG for this data and verify for yourself why each of these features should be true. 

This plot shows us that, if we want to estimate the effect of $X$ on $W$, we should use SNPs that affect $X$ only. If we also include SNPs with direct effects on $Z$, we will not be able to 
estimate the slope of the black line. We will see this below.

### Single Variable MR

A typical MR workflow might involve first selecting SNPs that are strongly associated with $X$ and then fitting single-variable MR. With this data, we expect this approach to be biased due to the heritable confounder $Z$. The plot below shows the effect estimates for SNPs selected according to their association p-value with $X$. Note that this data set was generated with large SNP effects and large sample size in order to better visualize the effects.  

```{r, fig.width=6}
# Dataframe of effect estimates
est_eff <- data.frame(bhat_x = sim_dat1$beta_hat[,1], 
                      bhat_w = sim_dat1$beta_hat[,4], 
                      se_bhat_x = sim_dat1$se_beta_hat[,1], 
                      se_bhat_w = sim_dat1$se_beta_hat[,4]) %>%
           mutate(p_val_x = 2*pnorm(-abs(bhat_x/se_bhat_x)))
est_eff$type <- te$type

# Variants we select for single-variable MR
sv_mr_inst <- filter(est_eff, p_val_x < 5e-8)

sv_mr_inst %>% 
ggplot() + 
  geom_point(aes(x = bhat_x, y = bhat_w, color = type), alpha = 0.6) + 
  theme_bw()
```

Next we fit single-variable MR using both all selecte instruments and restricting 
to only valid instruments (instruments with direct effects only on $X$). 

```{r}
mr_res1 <- mr_ivw(b_exp = sv_mr_inst$bhat_x, b_out = sv_mr_inst$bhat_w, 
       se_exp = sv_mr_inst$se_bhat_x, se_out = sv_mr_inst$se_bhat_w)

sv_mr_inst_xonly <- filter(est_eff, p_val_x < 5e-8 & type == "X Effect SNPs")
mr_res2 <- mr_ivw(b_exp = sv_mr_inst_xonly$bhat_x, b_out = sv_mr_inst_xonly$bhat_w, 
       se_exp = sv_mr_inst_xonly$se_bhat_x, se_out = sv_mr_inst_xonly$se_bhat_w)
```

The plot below shows the naive single-variable MR estimate (red), the estimate using only X effect SNPs (blue), and the truth (black). Dotted lines correspond to 95\% confidence intervals. 

```{r,  fig.width=6}
mr_slope <- data.frame(slope = c(mr_res1$b, 
                                 mr_res2$b, 
                                 sim_dat1$total_trait_effects[1,4]), 
                        col = c("red", "blue", "black"), 
                       lty = 1)

ci_slope <- data.frame(slope = c(mr_res1$b + c(-1, 1)*mr_res1$se*qnorm(0.975), 
                                 mr_res2$b + c(-1, 1)*mr_res2$se*qnorm(0.975)), 
                       col = rep(c("red", "blue"), each = 2), 
                       lty = 2)
mr_slope <- bind_rows(mr_slope, ci_slope)

sv_mr_inst %>% 
ggplot() + 
  geom_point(aes(x = bhat_x, y = bhat_w), alpha = 0.6) + 
  geom_abline(slope = mr_slope$slope, color = mr_slope$col, linetype = mr_slope$lty)

```

```{r}
sv_res <- data.frame(est = c(mr_res1$b, mr_res2$b, sim_dat1$total_trait_effects[1,4]), 
                     ci_lower = c(mr_res1$b-mr_res1$se*qnorm(0.975), 
                                  mr_res2$b-mr_res2$se*qnorm(0.975), 
                                  NA), 
                     ci_lower = c(mr_res1$b+mr_res1$se*qnorm(0.975), 
                                  mr_res2$b+mr_res2$se*qnorm(0.975), 
                                  NA),
                     type = c("Naive", "Valid Instruments Only", "Truth"))
sv_res
```


Note that even using only valid instruments, the estimate is still slightly low. 

### Multivariable MR

Excluding the Z-effect SNPs requires knowledge of the underlying truth which is unavailable in 
real problems. An alternative is to adjust for the heritable confounder in multivariable MR. 
We do this below with the `mv_multiple` function from `TwoSampleMR` which uses the 
regression multivariable MR strategy. Using this function requires a bit of data manipulation
to get the simulated data data into the required format. 

```{r}
exp <- sim_dat1$beta_hat[, c(1, 3)]
colnames(exp) <- c("X", "Z")
hdat <- list(exposure_beta = exp,
             exposure_pval = 2*pnorm(-abs(sim_dat1$beta_hat[,c(1, 3)]/sim_dat1$se_beta_hat[,c(1, 3)])),
             exposure_se = sim_dat1$se_beta_hat[,c(1, 3)],
             outcome_beta = sim_dat1$beta_hat[,4],
             outcome_pval = 2*pnorm(-abs(sim_dat1$beta_hat[,4]/sim_dat1$se_bet_hat[,4])),
             outcome_se = sim_dat1$se_beta_hat[,4],
             expname = data.frame(id.exposure = c("X", "Z"), exposure = c("X", "Z")), 
             outname = data.frame(id.outcome = "W", outcome = "W"))

mv_mr_T <- mv_multiple(hdat, pval_threshold=5e-8,
                      instrument_specific = TRUE)
mv_mr_T
```


The estimates from multivariable MR should estimate the total effect of $X$ on $W$, `r round(sim_dat1$total_trait_effects[1,4], digits = 3)` and the effect of $Z$ on $W$ that is not mediated by $X$ `r round(sim_dat1$direct_trait_effects[3,4], digits = 3)`. We
notice that with multivariable MR, the estimate of the $X$ on $W$ effect is much closer than we got using 
single-variable MR. However, the estimate of the $Z$ on $W$ effect is quite far off. 


We can explore the possible causes of this problem in two ways. First, we exclude all SNPs except 
for those with direct effects on either $X$ or $Z$. 


```{r}
ix <- which(te$type %in% c("X Effect SNPs", "Z Effect SNPs"))
exp <- sim_dat1$beta_hat[ix, c(1, 3)]
colnames(exp) <- c("X", "Z")
hdat <- list(exposure_beta = exp,
             exposure_pval = 2*pnorm(-abs(sim_dat1$beta_hat[ix,c(1, 3)]/sim_dat1$se_beta_hat[ix,c(1, 3)])),
             exposure_se = sim_dat1$se_beta_hat[ix,c(1, 3)],
             outcome_beta = sim_dat1$beta_hat[ix,4],
             outcome_pval = 2*pnorm(-abs(sim_dat1$beta_hat[ix,4]/sim_dat1$se_bet_hat[ix,4])),
             outcome_se = sim_dat1$se_beta_hat[ix,4],
             expname = data.frame(id.exposure = c("X", "Z"), exposure = c("X", "Z")), 
             outname = data.frame(id.outcome = "W", outcome = "W"))

mv_mr_T <- mv_multiple(hdat, pval_threshold=5e-8,
                      instrument_specific = TRUE)
mv_mr_T
```

We find that the problem still persists, so the issue is not pleiotropy. 

Next we fit the multivariable MR regression model substitituting the true effects for the
estimated effects. 

```{r}
exp <- sim_dat1$B[, c(1, 3)]
colnames(exp) <- c("X", "Z")
hdat <- list(exposure_beta = exp,
             exposure_pval = 2*pnorm(-abs(sim_dat1$B[,c(1, 3)]/sim_dat1$se_beta_hat[,c(1, 3)])),
             exposure_se = sim_dat1$se_beta_hat[,c(1, 3)],
             outcome_beta = sim_dat1$B[,4],
             outcome_pval = 2*pnorm(-abs(sim_dat1$B[,4]/sim_dat1$se_bet_hat[,4])),
             outcome_se = sim_dat1$se_beta_hat[,4],
             expname = data.frame(id.exposure = c("X", "Z"), exposure = c("X", "Z")), 
             outname = data.frame(id.outcome = "W", outcome = "W"))

mv_mr_T <- mv_multiple(hdat, pval_threshold=5e-8,
                      instrument_specific = TRUE)
mv_mr_T
```

We find that the estimate is now close to the true value. The problem has occurred because the 
linear regression approach to multivariable MR does not account for measurement error in the effect estimates.


We can further verify that this is the case by fitting the data using GRAPPLE, which does 
account for measurement error

```{r}
grapple_dat <- data.frame(cbind(sim_dat1$beta_hat[, c(1, 2, 3, 4)], 
                                sim_dat1$se_beta_hat[, c(1, 2, 3, 4)]))
names(grapple_dat) <- c("gamma_exp1", "gamma_exp2", "gamma_exp3", "gamma_out1", 
                        "se_exp1", "se_exp2", "se_exp3", "se_out1")

grapple_dat <- mutate(grapple_dat, 
                      pval_1 = 2*pnorm(-abs(gamma_exp1/se_exp1)),
                      pval_2 = 2*pnorm(-abs(gamma_exp2/se_exp2)), 
                      pval_3 = 2*pnorm(-abs(gamma_exp3/se_exp3)))
grapple_dat$selection_pvals <- with(grapple_dat, pmin(pval_3, pmin(pval_1, pval_2)))

res <- grappleRobustEst(data = grapple_dat, p.thres = 1e-3, plot.it =FALSE)

grapple_res <- data.frame(est = res$beta.hat, 
                          ci_lower = res$beta.hat - sqrt(diag(res$beta.var))*qnorm(0.975),
                          ci_upper = res$beta.hat + sqrt(diag(res$beta.var))*qnorm(0.975), 
                          truth = sim_dat1$direct_trait_effects[1:3,4])
grapple_res

```

The GRAPPLE estimates are much closer, though both CIs are just slightly closer to zero than 
the true effects


